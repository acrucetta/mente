<h2 id="elastic-search">Elastic Search</h2>
<p>Elastic search started off as a scalable Lucene; horizontally
scalable search engine. It has been a competitor for Hadoop, Spark, and
Flink</p>
<p>It’s a server that handles JSON requests.</p>
<h3 id="elastic-stack">Elastic Stack</h3>
<p><strong>Kibana</strong> - Web UI for searching and visualizing -
Complex aggregations, graphs, charts - Often used for log analysis</p>
<p>ES is not only for searching text anymore.</p>
<p><strong>Logstash / Beats</strong> - Ways to feed data into Elastic
Search - FileBeat can monitor log files, parse them, and import into
Elastic Search in near-real-time - Not just log files</p>
<p><strong>X-Pack</strong> - Security - Machine Learning - Graph
Exploration</p>
<h3 id="basic-concepts">Basic Concepts</h3>
<p><strong>Documents</strong>: - Row in the database - Something you’re
searching for - Any structured JSON data works - Every document has a
unique ID and a type</p>
<p>E.g.,</p>
<p>{ name: “baby carrots” category: “vegetables” brand: “365” }</p>
<p><strong>Indices</strong> - Highest level entity - Can contain
collection of types -&gt; collection of documents - Documents that share
similar traits are groupped into an index - Indices are just a virtual
representation; doesn’t store in disk</p>
<p><strong>Restful API</strong></p>
<p>ES works via HTTP requests and JSON data. Any language or tool that
can handle HTTP can use Elastic Search. You don’t need anything beyond
HTTP requests.</p>
<p><strong>Client APIs</strong></p>
<p>Most languages have specialized ES libraries</p>
<p><strong>Analytic Tools</strong></p>
<p>Web based UI to view indices and explore them without code</p>
<h2 id="architecture">Architecture</h2>
<p>Documents are hashed to a particular shard. Each shard may be on a
different node in a cluster. Every shard is a self-contained Lucene
index of its own.</p>
<p>The index has two primary shards and two replicas. The application
round robins requests among nodes.</p>
<p>Write requests are routed to the primary shard, then replicated.</p>
<p>Read requests are routed to the primary or any replicas</p>
<p>If we go over the amopunt of shards (200K documents) we can
horizontally scale to hold more data. Sharding speeds up the search. We
can run a search on all the shards in parallel.</p>
<p>To prevent losing data, elastic search replicates data across
clusters (cross-cluster replication). CCR provides a way to
automatically synchronize indices from your primary cluster to a
secondary remote cluster.</p>
<h3 id="sharding">Sharding</h3>
<p>Sharding allows us to divide indices into smaller pieces.</p>
<p>e.g., Node A (500 gb); Node B (500 gb)</p>
<p>Index (600 GB) gets placed into both indices.</p>
<ul>
<li>A shard is an independent index</li>
<li>A shard has no predefined size; it grows as documents are added</li>
<li>A shard may store up to about 2 billion documents</li>
</ul>
<p>Why we shard: - Allows us to store more documents - Easier to fit
large indices - Improved parallel performance</p>
<p>Configuring shards: - We use to have 5 shards by default - Indices
are now created with one shard by default - We can modify the shards
with the split/shrink API</p>
<p>How many shards: - If you anticipate millions of docs, consider a
couple of shards - Otherwise, use the default shards</p>
<h3 id="replication">Replication</h3>
<p>Elastic search natively supports replication. Setting it up can be
complicated.</p>
<p>How does replication work? - Replication creates copies of shards
(replica shards) - A shard that was replicated is called “Primary
shards”</p>
<p>Node B [Primary Shard B][Replica A1][Replica A2]</p>
<p>Choosing replicas: - How many replicas are ideal; depends on the use
case - IS the data stored elsewhere? - We should replicate shards at
least twice</p>
<p>Snapshots: - Snapshots are also back-ups - Snapshots can be taken at
the index level or for the entire cluster - We can take a snashot before
running a query; replication can’t help with this but it can with a
snapshot (rollback to snapshot)</p>
<p>Increasing throughput with replication: - Replica shards can serve
diff search requests simultaneously - Elastic can route to the best
shared - CPU paralellization can improve performance if multiple shards
are on the same node</p>
<h3 id="node-roles">Node Roles</h3>
<p>Default roles: dim (data, ingest, master)</p>
<p>Master node: - A node may be elected as the cluster’s master nodes -
A master node is responsible for creating and deleting indices</p>
<p>Data role: - Enables a node to store data - Storing data includes
performing queries related to that data, such as queries</p>
<p>Ingest role: - Node that ingests data - Ingest pipelines are a series
of steps performed when indexing documents - A simplified version of
Logstash, directly within Elastic search</p>
<p>Machine Learning - Identifies node as ML node - useful for running ML
jobs</p>
<p>Coordination nodes - Processes request; not possible for single
setting - Essentially a load balancer</p>
<p>When to change node roles: - It depends; useful for large clusters -
Typically done when optimizing the cluster to scale - Only change when
you know what you’re doing</p>
<h2 id="managing-documents">Managing Documents</h2>
<ul>
<li>Elastic search documents are immutable</li>
<li>The existing document is replaced with a modified document</li>
<li>We can do the same at the app level</li>
</ul>
<p><strong>Creating and deleting indices</strong></p>
<p>DELETE /pages</p>
<p>PUT /products { “settings” : { … } }</p>
<p>POST /products/_doc/100 { “name”:“Coffee Maker” “price”:64
“in_stock”:10 }</p>
<p>GET /product/_doc/100</p>
<p><strong>Update field</strong></p>
<p>POST /products/_update/100 { “doc: {”in_stock”:3 } }</p>
<p><strong>Add field</strong></p>
<p>POST /products/_update/100 { “doc: {”tags”: [“electronics”] } }</p>
<h2 id="commands">Commands</h2>
<ul>
<li>GET /cluster/health</li>
<li>GET /_cat/indices</li>
</ul>
