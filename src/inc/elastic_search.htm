<h2>Elastic Search</h2>
<p>Elastic search started off as a scalable Lucene; horizontally
scalable search engine. It has been a competitor for Hadoop, Spark, and
Flink</p>
<p>It's a server that handles JSON requests.</p>
<h3>Elastic Stack</h3>
<p><strong>Kibana</strong></p>
<ul>
<li>Web UI for searching and visualizing</li>
<li>Complex aggregations, graphs, charts</li>
<li>Often used for log analysis</li>
</ul>
<p>ES is not only for searching text anymore.</p>
<p><strong>Logstash / Beats</strong></p>
<ul>
<li>Ways to feed data into Elastic Search</li>
<li>FileBeat can monitor log files, parse them, and import into Elastic
Search in near-real-time</li>
<li>Not just log files</li>
</ul>
<p><strong>X-Pack</strong></p>
<ul>
<li>Security</li>
<li>Machine Learning</li>
<li>Graph Exploration</li>
</ul>
<h3>Basic Concepts</h3>
<p><strong>Documents</strong>:</p>
<ul>
<li>Row in the database</li>
<li>Something you're searching for</li>
<li>Any structured JSON data works</li>
<li>Every document has a unique ID and a type</li>
</ul>
<p>E.g.,</p>
<pre><code>\{
    name: &quot;baby carrots&quot;
    category: &quot;vegetables&quot;
    brand: &quot;365&quot;
\}</code></pre>
<p><strong>Indices</strong></p>
<ul>
<li>Highest level entity</li>
<li>Can contain collection of types -&gt; collection of documents</li>
<li>Documents that share similar traits are groupped into an index</li>
<li>Indices are just a virtual representation; doesn't store in
disk</li>
</ul>
<p><strong>Restful API</strong></p>
<p>ES works via HTTP requests and JSON data. Any language or tool that
can handle HTTP can use Elastic Search. You don't need anything beyond
HTTP requests.</p>
<p><strong>Client APIs</strong></p>
<p>Most languages have specialized ES libraries</p>
<p><strong>Analytic Tools</strong></p>
<p>Web based UI to view indices and explore them without code</p>
<h2>Architecture</h2>
<p>Documents are hashed to a particular shard. Each shard may be on a
different node in a cluster. Every shard is a self-contained Lucene
index of its own.</p>
<p>The index has two primary shards and two replicas. The application
round robins requests among nodes.</p>
<p>Write requests are routed to the primary shard, then replicated.</p>
<p>Read requests are routed to the primary or any replicas</p>
<p>If we go over the amopunt of shards (200K documents) we can
horizontally scale to hold more data. Sharding speeds up the search. We
can run a search on all the shards in parallel.</p>
<p>To prevent losing data, elastic search replicates data across
clusters (cross-cluster replication). CCR provides a way to
automatically synchronize indices from your primary cluster to a
secondary remote cluster.</p>
<h3>Sharding</h3>
<p>Sharding allows us to divide indices into smaller pieces.</p>
<p>e.g., Node A (500 gb); Node B (500 gb)</p>
<p>Index (600 GB) gets placed into both indices.</p>
<ul>
<li>A shard is an independent index</li>
<li>A shard has no predefined size; it grows as documents are added</li>
<li>A shard may store up to about 2 billion documents</li>
</ul>
<p>Why we shard:</p>
<ul>
<li>Allows us to store more documents</li>
<li>Easier to fit large indices</li>
<li>Improved parallel performance</li>
</ul>
<p>Configuring shards:</p>
<ul>
<li>We use to have 5 shards by default</li>
<li>Indices are now created with one shard by default</li>
<li>We can modify the shards with the split/shrink API</li>
</ul>
<p>How many shards:</p>
<ul>
<li>If you anticipate millions of docs, consider a couple of shards</li>
<li>Otherwise, use the default shards</li>
</ul>
<h3>Replication</h3>
<p>Elastic search natively supports replication. Setting it up can be
complicated.</p>
<p>How does replication work?</p>
<ul>
<li>Replication creates copies of shards (replica shards)</li>
<li>A shard that was replicated is called "Primary shards"</li>
</ul>
<p>Node B [Primary Shard B][Replica A1][Replica A2]</p>
<p>Choosing replicas:</p>
<ul>
<li>How many replicas are ideal; depends on the use case</li>
<li>IS the data stored elsewhere?</li>
<li>We should replicate shards at least twice</li>
</ul>
<p>Snapshots:</p>
<ul>
<li>Snapshots are also back-ups</li>
<li>Snapshots can be taken at the index level or for the entire
cluster</li>
<li>We can take a snashot before running a query; replication can't help
with this but it can with a snapshot (rollback to snapshot)</li>
</ul>
<p>Increasing throughput with replication:</p>
<ul>
<li>Replica shards can serve diff search requests simultaneously</li>
<li>Elastic can route to the best shared</li>
<li>CPU paralellization can improve performance if multiple shards are
on the same node</li>
</ul>
<h3>Node Roles</h3>
<p>Default roles: dim (data, ingest, master)</p>
<p>Master node:</p>
<ul>
<li>A node may be elected as the cluster's master nodes</li>
<li>A master node is responsible for creating and deleting indices</li>
</ul>
<p>Data role:</p>
<ul>
<li>Enables a node to store data</li>
<li>Storing data includes performing queries related to that data, such
as queries</li>
</ul>
<p>Ingest role:</p>
<ul>
<li>Node that ingests data</li>
<li>Ingest pipelines are a series of steps performed when indexing
documents</li>
<li>A simplified version of Logstash, directly within Elastic
search</li>
</ul>
<p>Machine Learning</p>
<ul>
<li>Identifies node as ML node</li>
<li>useful for running ML jobs</li>
</ul>
<p>Coordination nodes</p>
<ul>
<li>Processes request; not possible for single setting</li>
<li>Essentially a load balancer</li>
</ul>
<p>When to change node roles:</p>
<ul>
<li>It depends; useful for large clusters</li>
<li>Typically done when optimizing the cluster to scale</li>
<li>Only change when you know what you're doing</li>
</ul>
<h2>Managing Documents</h2>
<ul>
<li>Elastic search documents are immutable</li>
<li>The existing document is replaced with a modified document</li>
<li>We can do the same at the app level</li>
</ul>
<p><strong>Creating and deleting indices</strong></p>
<p>DELETE /pages</p>
<p>PUT /products { "settings" : { ... } }</p>
<p>POST /products/_doc/100 { "name":"Coffee Maker" "price":64
"in_stock":10 }</p>
<p>GET /product/_doc/100</p>
<p><strong>Update field</strong></p>
<p>POST /products/_update/100 { "doc: { "in_stock":3 } }</p>
<p><strong>Add field</strong></p>
<p>POST /products/_update/100 { "doc: { "tags": ["electronics"] } }</p>
<h2>Mapping &amp; Analysis</h2>
<h3>Analysis</h3>
<p>Text values are analyzed when indexing documents. Text is processed
before it's stored.</p>
<p>An analyzer has:</p>
<ul>
<li>Character filters
<ul>
<li>Adds, removes or changes characters</li>
<li>Char filters are applied in the order specified</li>
</ul></li>
<li>Tokenizer
<ul>
<li>Splitting text into tokens</li>
</ul></li>
<li>Token filters
<ul>
<li>Receive tokens</li>
<li>Apply filters to the tokens</li>
<li>e.g., lowercase filter</li>
</ul></li>
</ul>
<h3>Mapping</h3>
<p>Defines the structure of documents and how they're indexed and
stored. Similar to a schema in a relational database.</p>
<p>Approaches to mapping:</p>
<ul>
<li>Explicit mapping - defining it ourselves</li>
<li>Dynamic mapping - generating field mapping for us</li>
</ul>
<p>Data types:</p>
<ul>
<li>object data type: used for any json object
<ul>
<li>objects may be nested</li>
<li>mapped using the properties parameter</li>
<li>objects are not stored as objects in Apache Lucene</li>
<li>objects are flattened</li>
</ul></li>
<li>nested data type
<ul>
<li>maintains the relationship</li>
<li>we need to use a nested query to maintain the relationships</li>
</ul></li>
<li>keyword
<ul>
<li>used for exact matching of values</li>
<li>typically used for filtering, aggregations, and sorting</li>
<li>e.g., searching for articles with a given status</li>
</ul></li>
</ul>
<p>How the <em>keyword</em> data type works</p>
<ul>
<li>The keyword analyzer is a no-op analyzer. It outputs the text as a
single token</li>
<li>IN: "a blue duck" OUT: "a blue duck"</li>
</ul>
<p>Type coercion:</p>
<ul>
<li>Elastic search inspects data types when indexing</li>
<li>If we give 7.4, "7.4" and "7.4m" elastic search will coerce the
value to become a floating point number</li>
<li>The "_source" document contains the original document. The search
query uses indexed values, not _source (BKD trees, inverted
indices)</li>
</ul>
<h2>Searching for data</h2>
<h3>Query DSL</h3>
<pre><code>GET /products/_search 
\{
    &quot;query&quot; : \{
        &quot;match_all&quot; : \{\}
    \}
\}</code></pre>
<p><strong>Term level queries</strong></p>
<p>Term level queries are not analyzed. They are used as is. They can be
used with data types such as keyword, numbers, dates, etc...</p>
<p>Don't use them for text fields.</p>
<p>They are case sensitive.</p>
<pre><code>GET /products/_search 
\{
    &quot;query&quot; : \{
        &quot;term&quot; : \{
            &quot;brand.keyword&quot; : &quot;nike&quot; -- looks for specific term
        \}
    \}
\}</code></pre>
