<h2>Elastic Search</h2>
<p>Elastic search started off as a scalable Lucene; horizontally scalable search engine. It has been a competitor for Hadoop, Spark, and Flink</p>
<p>It's a server that handles JSON requests.</p>
<h3>Elastic Stack</h3>
<p><strong>Kibana</strong></p>
<ul>
<li>Web UI for searching and visualizing</li>
<li>Complex aggregations, graphs, charts</li>
<li>Often used for log analysis</li>
</ul>
<p>ES is not only for searching text anymore. </p>
<p><strong>Logstash / Beats</strong></p>
<ul>
<li>Ways to feed data into Elastic Search</li>
<li>FileBeat can monitor log files, parse them, and import into Elastic Search in near-real-time</li>
<li>Not just log files</li>
</ul>
<p><strong>X-Pack</strong></p>
<ul>
<li>Security</li>
<li>Machine Learning</li>
<li>Graph Exploration</li>
</ul>
<h3>Basic Concepts</h3>
<p><strong>Documents</strong>: </p>
<ul>
<li>Row in the database</li>
<li>Something you're searching for</li>
<li>Any structured JSON data works</li>
<li>Every document has a unique ID and a type</li>
</ul>
<p>E.g.,</p>
<p>{
name: &quot;baby carrots&quot;
category: &quot;vegetables&quot;
brand: &quot;365&quot;
}</p>
<p><strong>Indices</strong></p>
<ul>
<li>Highest level entity</li>
<li>Can contain collection of types -&gt; collection of documents</li>
<li>Documents that share similar traits are groupped into an index</li>
<li>Indices are just a virtual representation; doesn't store in disk</li>
</ul>
<p><strong>Restful API</strong></p>
<p>ES works via HTTP requests and JSON data. Any language or tool that can handle HTTP can use Elastic Search. You don't need anything beyond HTTP requests.</p>
<p><strong>Client APIs</strong></p>
<p>Most languages have specialized ES libraries</p>
<p><strong>Analytic Tools</strong></p>
<p>Web based UI to view indices and explore them without code</p>
<h2>Architecture</h2>
<p>Documents are hashed to a particular shard. Each shard may be on a different node in a cluster. Every shard is a self-contained Lucene index of its own.</p>
<p>The index has two primary shards and two replicas. The application round robins requests among nodes.</p>
<p>Write requests are routed to the primary shard, then replicated.</p>
<p>Read requests are routed to the primary or any replicas</p>
<p>If we go over the amopunt of shards (200K documents) we can horizontally scale to hold more data. Sharding speeds up the search. We can run a search on all the shards in parallel.</p>
<p>To prevent losing data, elastic search replicates data across clusters (cross-cluster replication). CCR provides a way to automatically synchronize indices from your primary cluster to a secondary remote cluster.</p>
<h3>Sharding</h3>
<p>Sharding allows us to divide indices into smaller pieces.</p>
<p>e.g., Node A (500 gb); Node B (500 gb)</p>
<p>Index (600 GB) gets placed into both indices.</p>
<ul>
<li>A shard is an independent index</li>
<li>A shard has no predefined size; it grows as documents are added</li>
<li>A shard may store up to about 2 billion documents</li>
</ul>
<p>Why we shard:</p>
<ul>
<li>Allows us to store more documents</li>
<li>Easier to fit large indices</li>
<li>Improved parallel performance</li>
</ul>
<p>Configuring shards:</p>
<ul>
<li>We use to have 5 shards by default</li>
<li>Indices are now created with one shard by default</li>
<li>We can modify the shards with the split/shrink API</li>
</ul>
<p>How many shards:</p>
<ul>
<li>If you anticipate millions of docs, consider a couple of shards</li>
<li>Otherwise, use the default shards</li>
</ul>
<h3>Replication</h3>
<p>Elastic search natively supports replication. Setting it up can be complicated.</p>
<p>How does replication work?</p>
<ul>
<li>Replication creates copies of shards (replica shards)</li>
<li>A shard that was replicated is called &quot;Primary shards&quot;</li>
</ul>
<p>Node B
[Primary Shard B][Replica A1][Replica A2]</p>
<p>Choosing replicas:</p>
<ul>
<li>How many replicas are ideal; depends on the use case</li>
<li>IS the data stored elsewhere?</li>
<li>We should replicate shards at least twice</li>
</ul>
<p>Snapshots:</p>
<ul>
<li>Snapshots are also back-ups</li>
<li>Snapshots can be taken at the index level or for the entire cluster</li>
<li>We can take a snashot before running a query; replication can't help with this but it can with a snapshot (rollback to snapshot)</li>
</ul>
<p>Increasing throughput with replication:</p>
<ul>
<li>Replica shards can serve diff search requests simultaneously</li>
<li>Elastic can route to the best shared</li>
<li>CPU paralellization can improve performance if multiple shards are on the same node</li>
</ul>
<h3>Node Roles</h3>
<p>Default roles: dim (data, ingest, master)</p>
<p>Master node:</p>
<ul>
<li>A node may be elected as the cluster's master nodes</li>
<li>A master node is responsible for creating and deleting indices</li>
</ul>
<p>Data role:</p>
<ul>
<li>Enables a node to store data</li>
<li>Storing data includes performing queries related to that data, such as queries</li>
</ul>
<p>Ingest role:</p>
<ul>
<li>Node that ingests data</li>
<li>Ingest pipelines are a series of steps performed when indexing documents </li>
<li>A simplified version of Logstash, directly within Elastic search</li>
</ul>
<p>Machine Learning</p>
<ul>
<li>Identifies node as ML node</li>
<li>useful for running ML jobs</li>
</ul>
<p>Coordination nodes</p>
<ul>
<li>Processes request; not possible for single setting</li>
<li>Essentially a load balancer</li>
</ul>
<p>When to change node roles:</p>
<ul>
<li>It depends; useful for large clusters</li>
<li>Typically done when optimizing the cluster to scale</li>
<li>Only change when you know what you're doing</li>
</ul>
<h2>Managing Documents</h2>
<ul>
<li>Elastic search documents are immutable</li>
<li>The existing document is replaced with a modified document</li>
<li>We can do the same at the app level</li>
</ul>
<p><strong>Creating and deleting indices</strong></p>
<p>DELETE /pages</p>
<p>PUT /products
{
&quot;settings&quot; : {
...
}
}</p>
<p>POST /products/_doc/100
{
&quot;name&quot;:&quot;Coffee Maker&quot;
&quot;price&quot;:64
&quot;in_stock&quot;:10
}</p>
<p>GET /product/_doc/100</p>
<p><strong>Update field</strong></p>
<p>POST /products/_update/100
{
&quot;doc: {
&quot;in_stock&quot;:3
}
}</p>
<p><strong>Add field</strong></p>
<p>POST /products/_update/100
{
&quot;doc: {
&quot;tags&quot;: [&quot;electronics&quot;]
}
}</p>
<h2>Commands</h2>
<ul>
<li>GET /cluster/health</li>
<li>GET /_cat/indices</li>
</ul>
